{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importation des librairies utilisées\n",
    "import unicodedata \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import collections\n",
    "import itertools\n",
    "import csv\n",
    "import warnings\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Répertoire de travail\n",
    "DATA_DIR = \"C:/Users/ETIENNE/Documents/Work/INSA/4A/Projets 4gmm 2018/\"\n",
    "\n",
    "# Nom des fichiers\n",
    "training_reduit_path = DATA_DIR + \"INSA_wefight_data_clean.csv\"\n",
    "# Variable Globale\n",
    "HEADER_TEST = ['Question','Intent','BlockId', 'Action']\n",
    "HEADER_TRAIN =['Question','Intent','BlockId', 'Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Takes 0 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Intent</th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>quels sont les effets du taxol et de l hormono...</td>\n",
       "      <td>#6-24_TRTEINS_hormonotherapie</td>\n",
       "      <td>59632c41e4b0a226d067cc6d</td>\n",
       "      <td>wiki_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>Qd les cheveux repoussent ils ?</td>\n",
       "      <td>#2-38_QVDP_Alopecie_Repousse</td>\n",
       "      <td>598434d5e4b03f0d12d31a20</td>\n",
       "      <td>wiki_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>j'ai un rendez 25/01/2011</td>\n",
       "      <td>conversation_rappel_rendezvous</td>\n",
       "      <td>596340b8e4b0a226d0f4e811</td>\n",
       "      <td>conversation_rappelRendezVous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>ma dose de traitement</td>\n",
       "      <td>Profile_write_doseTraitement</td>\n",
       "      <td>596340c2e4b0a226d0f53612</td>\n",
       "      <td>conversation_FichePatientWrite:doseTraitement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>influence de l'alimentation sur la maladie</td>\n",
       "      <td>#2-130_QVDP_Alimentation</td>\n",
       "      <td>5991c543e4b0b2045b0c568f</td>\n",
       "      <td>wiki_cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  \\\n",
       "2583  quels sont les effets du taxol et de l hormono...   \n",
       "1134                    Qd les cheveux repoussent ils ?   \n",
       "4886                          j'ai un rendez 25/01/2011   \n",
       "5001                              ma dose de traitement   \n",
       "822          influence de l'alimentation sur la maladie   \n",
       "\n",
       "                              Intent                   BlockId  \\\n",
       "2583   #6-24_TRTEINS_hormonotherapie  59632c41e4b0a226d067cc6d   \n",
       "1134    #2-38_QVDP_Alopecie_Repousse  598434d5e4b03f0d12d31a20   \n",
       "4886  conversation_rappel_rendezvous  596340b8e4b0a226d0f4e811   \n",
       "5001    Profile_write_doseTraitement  596340c2e4b0a226d0f53612   \n",
       "822         #2-130_QVDP_Alimentation  5991c543e4b0b2045b0c568f   \n",
       "\n",
       "                                             Action  \n",
       "2583                                    wiki_cancer  \n",
       "1134                                    wiki_cancer  \n",
       "4886                  conversation_rappelRendezVous  \n",
       "5001  conversation_FichePatientWrite:doseTraitement  \n",
       "822                                     wiki_cancer  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_dataset(input_path, nb_line, tauxValid,columns):\n",
    "    time_start = time.time()\n",
    "    data_all = pd.read_csv(input_path,sep=\",\",names=columns,nrows=nb_line) #cree data frame\n",
    "    data_all = data_all.fillna(\"\") #remplace les na par \" \"\n",
    "    data_train, data_valid = train_test_split(data_all, test_size = tauxValid) # Split arrays or matrices into random train and test subsets\n",
    "    time_end = time.time()\n",
    "    print(\"Split Takes %d s\" %(time_end-time_start))\n",
    "    return data_train, data_valid\n",
    "\n",
    "nb_line=20000  # part totale extraite du fichier initial ici déjà réduit\n",
    "tauxValid=0.10 # part totale extraite du fichier initial ici déjà réduit\n",
    "data_train, data_valid = split_dataset(training_reduit_path, nb_line, tauxValid, HEADER_TRAIN)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Librairies \n",
    "from bs4 import BeautifulSoup #Nettoyage d'HTML\n",
    "import re # Regex\n",
    "import nltk # Nettoyage des données\n",
    "\n",
    "## listes de mots à supprimer dans la description des produits\n",
    "## Depuis NLTK\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('french') \n",
    "## Depuis Un fichier externe.\n",
    "lucene_stopwords = [unicode(w, \"utf-8\") for w in open(DATA_DIR+\"lucene_stopwords.txt\").read().split(\",\")] #En local\n",
    "\n",
    "## Union des deux fichiers de stopwords \n",
    "stopwords = list(set(nltk_stopwords).union(set(lucene_stopwords)))\n",
    "\n",
    "## Fonction de setmming de stemming permettant la racinisation\n",
    "stemmer=nltk.stem.SnowballStemmer('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fonction clean générale\n",
    "def clean_txt(txt):\n",
    "    ### remove html stuff\n",
    "    txt = BeautifulSoup(txt,\"html.parser\",from_encoding='utf-8').get_text() #nettoyage donnee html\n",
    "    ### lower case\n",
    "    txt = txt.lower()\n",
    "    ### special escaping character '...'\n",
    "    txt = txt.replace(u'\\u2026','.')\n",
    "    txt = txt.replace(u'\\u00a0',' ')\n",
    "    ### remove accent btw\n",
    "    txt = unicodedata.normalize('NFD', txt).encode('ascii', 'ignore')\n",
    "    ###txt = unidecode(txt)\n",
    "    ### remove non alphanumeric char\n",
    "    txt = re.sub('[^a-z_]', ' ', txt)\n",
    "    ### remove french stop words\n",
    "    tokens = [w for w in txt.split() if (len(w)>2) and (w not in stopwords)]\n",
    "    ### french stemming\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    #Stemmers remove morphological affixes from words, leaving only the word stem\n",
    "    ### tokens = stemmer.stemWords(tokens)\n",
    "    return ' '.join(tokens)\n",
    "    #join() returns a string in which the string elements of sequence have been joined by str separator.\n",
    "\n",
    "def clean_marque(txt):\n",
    "    txt = re.sub('[^a-zA-Z0-9]', '_', txt).lower()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fonction de nettoyage du fichier(stemming et liste de mots à supprimer)\n",
    "def clean_df(input_data, column_names= ['Question','Intent','BlockId', 'Action']):\n",
    "    #Test if columns entry match columns names of input data\n",
    "    column_names_diff= set(column_names).difference(set(input_data.columns))\n",
    "    #set.difference   new set with elements in column_names but not in input_data.columns\n",
    "    \n",
    "    if column_names_diff: #rentre dans la boucle si column_names différent zero\n",
    "        # warning = exception\n",
    "        warnings.warn(\"Column(s) '\"+\", \".join(list(column_names_diff)) +\"' do(es) not match columns of input data\", Warning)\n",
    "        \n",
    "    nb_line = input_data.shape[0]\n",
    "    print(\"Start Clean %d lines\" %nb_line)\n",
    "    \n",
    "    # Cleaning start for each columns\n",
    "    time_start = time.time()\n",
    "    clean_list=[]\n",
    "    for column_name in column_names:\n",
    "        column = input_data[column_name].values\n",
    "        if column_name == \"Question\":\n",
    "            array_clean = np.array(map(clean_txt,column))\n",
    "            \n",
    "        elif column_name == \"Intent\":\n",
    "            array_clean = np.asarray(input_data['Intent']) #on recopie telle quelle la colonne intent  \n",
    "            \n",
    "        else:\n",
    "            array_clean = np.array(map(clean_marque,column))\n",
    "            #applies a function to all the items in an input_list\n",
    "            #map(function_to_apply, list_of_inputs)\n",
    "        clean_list.append(array_clean)\n",
    "    time_end = time.time()\n",
    "    print(\"Cleaning time: %d secondes\"%(time_end-time_start))\n",
    "    \n",
    "    #Convert list to DataFrame\n",
    "    array_clean = np.array(clean_list).T\n",
    "    data_clean = pd.DataFrame(array_clean, columns = column_names)\n",
    "    return data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Clean 502 lines\n",
      "Cleaning time: 0 secondes\n",
      "Start Clean 4511 lines\n",
      "Cleaning time: 4 secondes\n"
     ]
    }
   ],
   "source": [
    "# Take approximately 2 minutes fors 100.000 rows\n",
    "data_valid_clean = clean_df(data_valid)\n",
    "data_train_clean = clean_df(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_valid_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction import FeatureHasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorizer_train(df,column):\n",
    "    col = df[column]\n",
    "    # TFIDF\n",
    "    vec = TfidfVectorizer(\n",
    "            min_df = 1, #on prend tous les mots\n",
    "            stop_words =stopwords,\n",
    "            smooth_idf=True,\n",
    "            norm='l2',\n",
    "            sublinear_tf=True,\n",
    "            use_idf=True, #tf avec idf\n",
    "            ngram_range=(1,1)) \n",
    "    tfidf=vec.fit_transform(col)\n",
    "    return vec,tfidf\n",
    "\n",
    "def apply_vectorizer(df, vec, columns):\n",
    "    \n",
    "    data_hash = map(lambda x : \" \".join(x), df[columns].values)  \n",
    "    tfidf=vec.transform(df[columns])\n",
    "\n",
    "    # TFIDF\n",
    "    #tfidf=vec.transform(df)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec,X = vectorizer_train(data_train_clean,\"Question\")\n",
    "Y = data_train_clean[\"Intent\"].values\n",
    "Xv = apply_vectorizer(data_valid_clean,vec,\"Question\")\n",
    "Yv = data_valid_clean[\"Intent\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<502x1935 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 1341 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# training score:', 0.79716249168698738)\n"
     ]
    }
   ],
   "source": [
    "# Regression Logistique \n",
    "## estimation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#si on augmente C, on augmente bcp le score\n",
    "cla = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1, fit_intercept=True,\n",
    "                          intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear',\n",
    "                          max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "cla.fit(X,Y)\n",
    "score=cla.score(X,Y)\n",
    "Y_predict = cla.predict(X)\n",
    "                \n",
    "print('# training score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# validation score:', 0.6394422310756972)\n"
     ]
    }
   ],
   "source": [
    "## erreur en validation\n",
    "scoreValidation=cla.score(Xv,Yv)\n",
    "predict_v = cla.predict(Xv)\n",
    "##probleme car tfidf et Xv pas le même nbre de colonne \n",
    "print('# validation score:',scoreValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#6-49_TRTEINS_Peau', 59),\n",
       " ('#2-130_QVDP_Alimentation', 29),\n",
       " ('#2-36_QVDP_Alopecie_Pourquoi', 22),\n",
       " ('#6-60_TRTEINS_PAC', 21),\n",
       " ('#6-1_TRTEINS_Chimiotherapie', 19),\n",
       " ('#2-55_QVDP_Douleur', 17),\n",
       " ('#9-2_Informations_cancer', 17),\n",
       " ('#6-98_TRTEINS_EI_Frequents', 15),\n",
       " ('#2-107_QVDP_Grossesse', 15),\n",
       " ('#6-97_TRTEINS_Nausees_Vomissements', 14),\n",
       " ('#6-18_TRTEINS_Radiotherapie', 14),\n",
       " ('#6-53_TRTEINS_Aphtes', 11),\n",
       " ('#2-45_QVDP_Alopecie_Perruque', 11),\n",
       " ('#6-90_TRTEINS_Mauvais_Gout', 10),\n",
       " ('#2-64-0_QVDP_Fatigue', 10),\n",
       " ('#2-96_QVDP_Social_Priseencharge', 9),\n",
       " ('#6-41_TRTEINS_ManchonLymphodeme', 8),\n",
       " ('#6-73_TRTEINS_Chirurgie_Mastectomie', 8),\n",
       " ('#6-92_TRTEINS_Diarrhee', 8),\n",
       " ('#6-57_TRTEINS_Yeux_Secs', 7),\n",
       " ('#2-120_QVDP_Sexualite', 7),\n",
       " ('#2-115_QVDP_Grossesse_Allaitement', 7),\n",
       " ('#9-53_Informations_depistagesein', 6),\n",
       " ('#6-58_TRTEINS_Bouche_Seche', 6),\n",
       " ('conversation_rappel_rendezvous', 6),\n",
       " ('#2-125_QVDP_Sexualite_Reconstruction', 5),\n",
       " ('#6-67_TRTEINS_Chirurgie_Questions', 5),\n",
       " ('#7-52_Remission', 5),\n",
       " ('#2-103_QVDP_Social_Banque', 5),\n",
       " ('#2-128_QVDP_Sexualite_Couple', 5),\n",
       " ('#2-48_QVDP_Alopecie_RbPerruque', 5),\n",
       " ('#6-34_TRTEINS_Lymphoedeme', 5),\n",
       " ('#2-73_QVDP_Sport', 5),\n",
       " ('#2-87_QVDP_Fertilite', 5),\n",
       " ('#6-24_TRTEINS_hormonotherapie', 5),\n",
       " ('#2-135_QVDP_Alimentation_Alcool', 4),\n",
       " ('#5-37_Soutien_Psychologique', 4),\n",
       " ('#6-96_TRTEINS_Perte_Poids', 4),\n",
       " ('Conversation_rappel_update2', 4),\n",
       " ('#2-58_QVDP_RadioT_Eff', 3),\n",
       " ('#6-31_TRTEINS_Effetsecondaireshormonotherapie', 3),\n",
       " ('#6-40_TRTEINS_PressotherapieLymphodeme', 3),\n",
       " ('#6-65_TRTEINS_Chirurgie', 3),\n",
       " ('#9-13_Informations_metastase', 3),\n",
       " ('#2-41_QVDP_Alopecie_Diminuer', 3),\n",
       " ('#2-109_QVDP_Grossesse_Chimiotherapie', 3),\n",
       " ('#6-93_TRTEINS_Mauvaise_Haleine', 3),\n",
       " ('#2-97_QVDP_ResteACharge', 2),\n",
       " ('#2-53_QVDP_Cils', 2),\n",
       " ('#2-52_QVDP_Ongles', 2),\n",
       " ('#001_Gestion_Abonnement', 2),\n",
       " ('#2-106_QVDP_Social_HAD', 2),\n",
       " ('#2-70_QVDP_Fatigue_Diminuer', 2),\n",
       " ('#2-49_QVDP_Alopecie_OuPerruque', 2),\n",
       " ('#6-86_TRTEINS_Chirurgie_Reeducation', 2),\n",
       " ('#2-38_QVDP_Alopecie_Repousse', 2),\n",
       " ('#7-58_Recidive', 2),\n",
       " ('#2-126_QVDP_Sexualite_BaisseLibido', 2),\n",
       " ('#2-37_QVDP_Alopecie_Quand', 2),\n",
       " ('#2-90_QVDP_Fertilite_Ponction', 2),\n",
       " ('#2-79_QVDP_SportQuel', 2),\n",
       " ('Conversation_rappel_read', 2),\n",
       " ('#6-95_TRTEINS_Perte_Appetit', 2),\n",
       " ('#6-83_TRTEINS_Prothese', 2),\n",
       " ('#1-5_Menu_Aidant', 1),\n",
       " ('#8-9_DDP_Charte_patient', 1),\n",
       " ('#2-75_QVDP_SportPrecautions', 1),\n",
       " ('#2-118_QVDP_Grossesse_Malformations', 1),\n",
       " ('#2-84_QVDP_Fertilite_GrossesseApresCancer', 1),\n",
       " ('#2-137_QVDP_Alimentation_Remboursement', 1),\n",
       " ('#2-121_QVDP_Sexualite_Cicatrice', 1),\n",
       " ('#2-61_QVDP_RadioT_Peau', 1),\n",
       " ('#2-110_QVDP_Grossesse_Radiotherapie', 1),\n",
       " ('#1-8_Menu_Traitement', 1),\n",
       " ('#2-72_QVDP_Fatigue_Sieste', 1),\n",
       " ('#2-93_QVDP_Social_Proches', 1),\n",
       " ('#2-59_QVDP_RadioT_Fatigue', 1),\n",
       " ('#2-134_QVDP_Alimentation_Citron', 1),\n",
       " ('#2-65_QVDP_Fatigue_Hormono', 1),\n",
       " ('#7-49_QVDA_Personne_de_confiance', 1),\n",
       " ('#6-23_TRTEINS_SeanceRadiotherapie', 1),\n",
       " ('#6-12_TRTEINS_ChimioAmbulatoire', 1),\n",
       " ('#2-102_QVDP_Social_RbPerruque', 1),\n",
       " ('#9-20_Informations_Stades', 1),\n",
       " ('#2-42_QVDP_Alopecie_Casque', 1),\n",
       " ('#2-85_QVDP_Fertilite_Preserver', 1)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(collections.Counter(predict_v).items(), key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F test\n",
    "\n",
    "precision (also called positive predictive value) is the fraction of relevant instances among the retrieved (= extrait) instances\n",
    "\n",
    "\n",
    "\n",
    "recall (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. Both precision and recall are therefore based on an understanding and measure of relevance.\n",
    "\n",
    "\n",
    "\n",
    "Example : Suppose a computer program for recognizing dogs in photographs identifies 8 dogs in a picture containing 12 dogs and some cats. Of the 8 dogs identified, 5 actually are dogs (true positives), while the rest are cats (false positives). The program's precision is 5/8 while its recall is 5/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les problèmes : Xv et X ne sont pas de même taille, Xv est plus petit. On cut X pour avoir la même taille que Xv ou on fait un tirage aleatoire?\n",
    "\n",
    "\n",
    "En essayant de cut, j'ai tjrs pas reussis ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-03fce471b573>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXvListe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXListe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"macro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "f1_score(XvListe,XListe,\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502, 1935)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502, 1935)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X[:502,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 1, 2, 2, 0, 2]\n",
    "y_pred = [6, 2, 1, 5, 0, 1]\n",
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-baf307f8c509>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.35\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\ranking.pyc\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    275\u001b[0m     return _average_binary_score(\n\u001b[0;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\base.pyc\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
