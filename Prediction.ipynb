{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce calepin s'organise en plusieurs points :\n",
    "- on extrait de notre data frame un échantillon qui aura pour but d'apprendre le modèle et un autre qui aura pour but de tester si l'apprentissage réalisé à été bien fait\n",
    "- nettoyage basique des données et utilisation des stopwords francais courant\n",
    "- on vectorise nos données en utilisant le tf idf\n",
    "- on applique une méthode d'apprentissage, la regression logistique\n",
    "- on évalue la pertinence de nos résultats avec un score\n",
    "- on cherche à voir si ce score est significatif ( F test, courbe roc .......)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importation des librairies utilisées\n",
    "import unicodedata \n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import collections\n",
    "import itertools\n",
    "import csv\n",
    "import warnings\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Répertoire de travail\n",
    "DATA_DIR = \"C:/Users/ETIENNE/Documents/Work/INSA/4A/Projets 4gmm 2018/\"\n",
    "\n",
    "# Nom des fichiers\n",
    "training_reduit_path = DATA_DIR + \"INSA_wefight_data_clean.csv\"\n",
    "# Variable Globale\n",
    "HEADER_TEST = ['Question','Intent','BlockId', 'Action']\n",
    "HEADER_TRAIN =['Question','Intent','BlockId', 'Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Takes 0 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Intent</th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>le cancer me fatigue</td>\n",
       "      <td>#2-64-0_QVDP_Fatigue</td>\n",
       "      <td>59942265e4b068eebf52bb9f</td>\n",
       "      <td>wiki_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>je ne crois plus en ma sensualité</td>\n",
       "      <td>#2-124_QVDP_Sexualite_PerteConfiance</td>\n",
       "      <td>59918a9ce4b0feb288722cc1</td>\n",
       "      <td>wiki_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>je suis seul</td>\n",
       "      <td>#2-93_QVDP_Social_Proches</td>\n",
       "      <td>598b430ae4b03f0d36d2626c</td>\n",
       "      <td>wiki_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>Je n ai pas le moral</td>\n",
       "      <td>#5-37_Soutien_Psychologique</td>\n",
       "      <td>59632c41e4b0a226d067c7ba</td>\n",
       "      <td>wiki_cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>Je sais que je veux être reconstruite rapideme...</td>\n",
       "      <td>#2-125_QVDP_Sexualite_Reconstruction</td>\n",
       "      <td>59918ad1e4b0feb288736b42</td>\n",
       "      <td>wiki_cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  \\\n",
       "1703                               le cancer me fatigue   \n",
       "574                   je ne crois plus en ma sensualité   \n",
       "2114                                       je suis seul   \n",
       "2233                               Je n ai pas le moral   \n",
       "631   Je sais que je veux être reconstruite rapideme...   \n",
       "\n",
       "                                    Intent                   BlockId  \\\n",
       "1703                  #2-64-0_QVDP_Fatigue  59942265e4b068eebf52bb9f   \n",
       "574   #2-124_QVDP_Sexualite_PerteConfiance  59918a9ce4b0feb288722cc1   \n",
       "2114             #2-93_QVDP_Social_Proches  598b430ae4b03f0d36d2626c   \n",
       "2233           #5-37_Soutien_Psychologique  59632c41e4b0a226d067c7ba   \n",
       "631   #2-125_QVDP_Sexualite_Reconstruction  59918ad1e4b0feb288736b42   \n",
       "\n",
       "           Action  \n",
       "1703  wiki_cancer  \n",
       "574   wiki_cancer  \n",
       "2114  wiki_cancer  \n",
       "2233  wiki_cancer  \n",
       "631   wiki_cancer  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_dataset(input_path, nb_line, tauxValid,columns):\n",
    "    time_start = time.time()\n",
    "    data_all = pd.read_csv(input_path,sep=\",\",names=columns,nrows=nb_line) #cree data frame\n",
    "    data_all = data_all.fillna(\"\") #remplace les na par \" \"\n",
    "    data_train, data_valid = train_test_split(data_all, test_size = tauxValid) # Split arrays or matrices into random train and test subsets\n",
    "    time_end = time.time()\n",
    "    print(\"Split Takes %d s\" %(time_end-time_start))\n",
    "    return data_train, data_valid\n",
    "\n",
    "nb_line=20000  # part totale extraite du fichier initial ici déjà réduit\n",
    "tauxValid=0.10 # part totale extraite du fichier initial ici déjà réduit\n",
    "data_train, data_valid = split_dataset(training_reduit_path, nb_line, tauxValid, HEADER_TRAIN)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Librairies \n",
    "from bs4 import BeautifulSoup #Nettoyage d'HTML\n",
    "import re # Regex\n",
    "import nltk # Nettoyage des données\n",
    "\n",
    "## listes de mots à supprimer dans la description des produits\n",
    "## Depuis NLTK\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('french') \n",
    "## Depuis Un fichier externe.\n",
    "lucene_stopwords = [unicode(w, \"utf-8\") for w in open(DATA_DIR+\"lucene_stopwords.txt\").read().split(\",\")] #En local\n",
    "\n",
    "## Union des deux fichiers de stopwords \n",
    "stopwords = list(set(nltk_stopwords).union(set(lucene_stopwords)))\n",
    "\n",
    "## Fonction de setmming de stemming permettant la racinisation\n",
    "stemmer=nltk.stem.SnowballStemmer('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fonction clean générale\n",
    "def clean_txt(txt):\n",
    "    ### remove html stuff\n",
    "    txt = BeautifulSoup(txt,\"html.parser\",from_encoding='utf-8').get_text() #nettoyage donnee html\n",
    "    ### lower case\n",
    "    txt = txt.lower()\n",
    "    ### special escaping character '...'\n",
    "    txt = txt.replace(u'\\u2026','.')\n",
    "    txt = txt.replace(u'\\u00a0',' ')\n",
    "    ### remove accent btw\n",
    "    txt = unicodedata.normalize('NFD', txt).encode('ascii', 'ignore')\n",
    "    ###txt = unidecode(txt)\n",
    "    ### remove non alphanumeric char\n",
    "    txt = re.sub('[^a-z_]', ' ', txt)\n",
    "    ### remove french stop words\n",
    "    tokens = [w for w in txt.split() if (len(w)>2) and (w not in stopwords)]\n",
    "    ### french stemming\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    #Stemmers remove morphological affixes from words, leaving only the word stem\n",
    "    ### tokens = stemmer.stemWords(tokens)\n",
    "    return ' '.join(tokens)\n",
    "    #join() returns a string in which the string elements of sequence have been joined by str separator.\n",
    "\n",
    "def clean_marque(txt):\n",
    "    txt = re.sub('[^a-zA-Z0-9]', '_', txt).lower()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fonction de nettoyage du fichier(stemming et liste de mots à supprimer)\n",
    "def clean_df(input_data, column_names= ['Question','Intent','BlockId', 'Action']):\n",
    "    #Test if columns entry match columns names of input data\n",
    "    column_names_diff= set(column_names).difference(set(input_data.columns))\n",
    "    #set.difference   new set with elements in column_names but not in input_data.columns\n",
    "    \n",
    "    if column_names_diff: #rentre dans la boucle si column_names différent zero\n",
    "        # warning = exception\n",
    "        warnings.warn(\"Column(s) '\"+\", \".join(list(column_names_diff)) +\"' do(es) not match columns of input data\", Warning)\n",
    "        \n",
    "    nb_line = input_data.shape[0]\n",
    "    print(\"Start Clean %d lines\" %nb_line)\n",
    "    \n",
    "    # Cleaning start for each columns\n",
    "    time_start = time.time()\n",
    "    clean_list=[]\n",
    "    for column_name in column_names:\n",
    "        column = input_data[column_name].values\n",
    "        if column_name == \"Question\":\n",
    "            array_clean = np.array(map(clean_txt,column))\n",
    "            \n",
    "        elif column_name == \"Intent\":\n",
    "            array_clean = np.asarray(input_data['Intent']) #on recopie telle quelle la colonne intent  \n",
    "            \n",
    "        else:\n",
    "            array_clean = np.array(map(clean_marque,column))\n",
    "            #applies a function to all the items in an input_list\n",
    "            #map(function_to_apply, list_of_inputs)\n",
    "        clean_list.append(array_clean)\n",
    "    time_end = time.time()\n",
    "    print(\"Cleaning time: %d secondes\"%(time_end-time_start))\n",
    "    \n",
    "    #Convert list to DataFrame\n",
    "    array_clean = np.array(clean_list).T\n",
    "    data_clean = pd.DataFrame(array_clean, columns = column_names)\n",
    "    return data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Clean 502 lines\n",
      "Cleaning time: 0 secondes\n",
      "Start Clean 4511 lines\n",
      "Cleaning time: 3 secondes\n"
     ]
    }
   ],
   "source": [
    "# Take approximately 2 minutes fors 100.000 rows\n",
    "data_valid_clean = clean_df(data_valid)\n",
    "data_train_clean = clean_df(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_valid_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction import FeatureHasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorizer_train(df,column):\n",
    "    col = df[column]\n",
    "    # TFIDF\n",
    "    vec = TfidfVectorizer(\n",
    "            min_df = 1, #on prend tous les mots\n",
    "            stop_words =stopwords,\n",
    "            smooth_idf=True,\n",
    "            norm='l2',\n",
    "            sublinear_tf=True,\n",
    "            use_idf=True, #tf avec idf\n",
    "            ngram_range=(1,1)) \n",
    "    tfidf=vec.fit_transform(col)\n",
    "    return vec,tfidf\n",
    "\n",
    "def apply_vectorizer(df, vec, columns):\n",
    "    \n",
    "    data_hash = map(lambda x : \" \".join(x), df[columns].values)  \n",
    "    tfidf=vec.transform(df[columns])\n",
    "\n",
    "    # TFIDF\n",
    "    #tfidf=vec.transform(df)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data_train est le jeux de donnée ou l'on fait l'apprentissage, X est composé des questions. Y est le jeux de donnée d'apprentissage comprendant les labels\n",
    "\n",
    "data_valid_clean contient un échantillon de test qui consiste à valider le modele ou non,Xv est composé des questions et Yv des labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec,X = vectorizer_train(data_train_clean,\"Question\")\n",
    "Y = data_train_clean[\"Intent\"].values\n",
    "Xv = apply_vectorizer(data_valid_clean,vec,\"Question\")\n",
    "Yv = data_valid_clean[\"Intent\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<502x1939 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 1353 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression logistique, pour faire apprendre au modele, on se sert alors de X et Y. Le training score est la comparaison des labels appris avec les vrai labels de X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# training score:', 0.80004433606739078)\n"
     ]
    }
   ],
   "source": [
    "# Regression Logistique \n",
    "## estimation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#si on augmente C, on augmente bcp le score\n",
    "cla = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1, fit_intercept=True,\n",
    "                          intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear',\n",
    "                          max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "cla.fit(X,Y)\n",
    "score=cla.score(X,Y)\n",
    "Y_predict = cla.predict(X)\n",
    "                \n",
    "print('# training score:',score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On compare l'apprentissage au modele de validation, c'est validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('# validation score:', 0.6633466135458167)\n"
     ]
    }
   ],
   "source": [
    "## erreur en validation\n",
    "scoreValidation=cla.score(Xv,Yv)\n",
    "predict_v = cla.predict(Xv)\n",
    "##probleme car tfidf et Xv pas le même nbre de colonne \n",
    "print('# validation score:',scoreValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#6-49_TRTEINS_Peau', 52),\n",
       " ('#2-130_QVDP_Alimentation', 28),\n",
       " ('#9-2_Informations_cancer', 24),\n",
       " ('#6-90_TRTEINS_Mauvais_Gout', 20),\n",
       " ('#6-92_TRTEINS_Diarrhee', 17),\n",
       " ('#6-60_TRTEINS_PAC', 15),\n",
       " ('#6-1_TRTEINS_Chimiotherapie', 14),\n",
       " ('#6-97_TRTEINS_Nausees_Vomissements', 14),\n",
       " ('#2-55_QVDP_Douleur', 12),\n",
       " ('#6-18_TRTEINS_Radiotherapie', 12),\n",
       " ('#2-96_QVDP_Social_Priseencharge', 11),\n",
       " ('#2-120_QVDP_Sexualite', 11),\n",
       " ('#2-107_QVDP_Grossesse', 11),\n",
       " ('#2-36_QVDP_Alopecie_Pourquoi', 10),\n",
       " ('#6-53_TRTEINS_Aphtes', 10),\n",
       " ('#6-98_TRTEINS_EI_Frequents', 10),\n",
       " ('#2-45_QVDP_Alopecie_Perruque', 10),\n",
       " ('#6-57_TRTEINS_Yeux_Secs', 9),\n",
       " ('#2-64-0_QVDP_Fatigue', 9),\n",
       " ('#2-73_QVDP_Sport', 8),\n",
       " ('#6-34_TRTEINS_Lymphoedeme', 8),\n",
       " ('#6-58_TRTEINS_Bouche_Seche', 8),\n",
       " ('#6-24_TRTEINS_hormonotherapie', 8),\n",
       " ('conversation_rappel_rendezvous', 8),\n",
       " ('#6-96_TRTEINS_Perte_Poids', 7),\n",
       " ('#2-128_QVDP_Sexualite_Couple', 6),\n",
       " ('#2-90_QVDP_Fertilite_Ponction', 6),\n",
       " ('#6-83_TRTEINS_Prothese', 6),\n",
       " ('#2-125_QVDP_Sexualite_Reconstruction', 5),\n",
       " ('#2-58_QVDP_RadioT_Eff', 5),\n",
       " ('#6-73_TRTEINS_Chirurgie_Mastectomie', 5),\n",
       " ('#2-48_QVDP_Alopecie_RbPerruque', 5),\n",
       " ('#9-53_Informations_depistagesein', 4),\n",
       " ('#6-31_TRTEINS_Effetsecondaireshormonotherapie', 4),\n",
       " ('#6-65_TRTEINS_Chirurgie', 4),\n",
       " ('#6-73_TRTEINS_Chirurgie_Curage_axillaire', 4),\n",
       " ('#2-79_QVDP_SportQuel', 4),\n",
       " ('#2-42_QVDP_Alopecie_Casque', 4),\n",
       " ('#2-135_QVDP_Alimentation_Alcool', 3),\n",
       " ('#5-37_Soutien_Psychologique', 3),\n",
       " ('#2-97_QVDP_ResteACharge', 3),\n",
       " ('#1-5_Menu_Aidant', 3),\n",
       " ('#6-41_TRTEINS_ManchonLymphodeme', 3),\n",
       " ('#2-52_QVDP_Ongles', 3),\n",
       " ('#2-49_QVDP_Alopecie_OuPerruque', 3),\n",
       " ('#2-61_QVDP_RadioT_Peau', 3),\n",
       " ('#2-38_QVDP_Alopecie_Repousse', 3),\n",
       " ('#7-52_Remission', 3),\n",
       " ('#2-133_QVDP_RegimeAnticancer', 3),\n",
       " ('#7-49_QVDA_Personne_de_confiance', 3),\n",
       " ('Conversation_rappel_read', 3),\n",
       " ('Conversation_rappel_update2', 3),\n",
       " ('#6-93_TRTEINS_Mauvaise_Haleine', 3),\n",
       " ('#2-53_QVDP_Cils', 2),\n",
       " ('#2-106_QVDP_Social_HAD', 2),\n",
       " ('#2-70_QVDP_Fatigue_Diminuer', 2),\n",
       " ('#6-39_TRTEINS_DrainageLymphodeme', 2),\n",
       " ('#1-4_Menu_Patient_Recent', 2),\n",
       " ('#2-103_QVDP_Social_Banque', 2),\n",
       " ('#1-8_Menu_Traitement', 2),\n",
       " ('#2-93_QVDP_Social_Proches', 2),\n",
       " ('#2-126_QVDP_Sexualite_BaisseLibido', 2),\n",
       " ('#2-41_QVDP_Alopecie_Diminuer', 2),\n",
       " ('#2-115_QVDP_Grossesse_Allaitement', 2),\n",
       " ('#6-33_TRTEINS_Lymphe', 2),\n",
       " ('#2-109_QVDP_Grossesse_Chimiotherapie', 2),\n",
       " ('#6-95_TRTEINS_Perte_Appetit', 2),\n",
       " ('#2-87_QVDP_Fertilite', 2),\n",
       " ('#6-67_TRTEINS_Chirurgie_Questions', 1),\n",
       " ('#6-72_TRTEINS_Chirurgie_Cicatrice', 1),\n",
       " ('#001_Gestion_Abonnement', 1),\n",
       " ('#2-100_QVDP_Social_Transports', 1),\n",
       " ('#2-121_QVDP_Sexualite_Cicatrice', 1),\n",
       " ('#6-40_TRTEINS_PressotherapieLymphodeme', 1),\n",
       " ('#8-6_DDP_Consentement_eclaire', 1),\n",
       " ('#2-37_QVDP_Alopecie_Quand', 1),\n",
       " ('#7-58_Recidive', 1),\n",
       " ('#2-72_QVDP_Fatigue_Sieste', 1),\n",
       " ('#9-13_Informations_metastase', 1),\n",
       " ('#2-59_QVDP_RadioT_Fatigue', 1),\n",
       " ('#2-65_QVDP_Fatigue_Hormono', 1),\n",
       " ('#2-101_QVDP_Social_RbProthese', 1),\n",
       " ('#2-64_QVDP_Fatigue_Chimio', 1),\n",
       " ('#6-13_TRTEINS_PreparationChimio', 1),\n",
       " ('#2-102_QVDP_Social_RbPerruque', 1),\n",
       " ('#2-84_QVDP_Fertilite_GrossesseApresCancer', 1),\n",
       " ('#2-85_QVDP_Fertilite_Preserver', 1)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#on regarde comment on a predit Xv qui est notre modele de validation\n",
    "sorted(collections.Counter(predict_v).items(), key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On compte a la main combien il y a de '#6-49_TRTEINS_Peau', il y en a 22 sur les 52 prédits, donc on voit clairement que l'apprentissage est mal fait, on range toutes les petites catégories dans la plus grosse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "compteur = 0\n",
    "for k in range (np.shape(data_valid_clean)[0]):\n",
    "    if data_valid_clean[\"Intent\"][k] == '#6-49_TRTEINS_Peau':\n",
    "        compteur = compteur + 1\n",
    "print(compteur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F test\n",
    "\n",
    "precision (also called positive predictive value) is the fraction of relevant instances among the retrieved (= extrait) instances\n",
    "\n",
    "\n",
    "\n",
    "recall (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. Both precision and recall are therefore based on an understanding and measure of relevance.\n",
    "\n",
    "\n",
    "\n",
    "Example : Suppose a computer program for recognizing dogs in photographs identifies 8 dogs in a picture containing 12 dogs and some cats. Of the 8 dogs identified, 5 actually are dogs (true positives), while the rest are cats (false positives). The program's precision is 5/8 while its recall is 5/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les problèmes : Xv et X ne sont pas de même taille, Xv est plus petit. On cut X pour avoir la même taille que Xv ou on fait un tirage aleatoire?\n",
    "\n",
    "\n",
    "En essayant de cut, j'ai tjrs pas reussis ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<502x1939 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 1353 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-ca7cdbd0e424>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\"macro\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "f1_score(Yv, Y ,\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502, 1939)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502, 1939)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X[:502,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ETIENNE\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 1, 2, 2, 0, 2]\n",
    "y_pred = [6, 2, 1, 5, 0, 1]\n",
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
